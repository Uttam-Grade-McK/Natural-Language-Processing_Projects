{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kiwi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/kiwi/Downloads/Data Scientist/Edureka_Projects/corpusd_cleandata/Extracted_Json.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0bf5a66d9a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_description\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/kiwi/Downloads/Data Scientist/Edureka_Projects/corpusd_cleandata/Extracted_Json.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m         )\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/kiwi/Downloads/Data Scientist/Edureka_Projects/corpusd_cleandata/Extracted_Json.csv'"
     ]
    }
   ],
   "source": [
    "df_description=pd.read_csv('/Users/kiwi/Downloads/Data Scientist/Edureka_Projects/corpusd_cleandata/Extracted_Json.csv')\n",
    "df_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fencing of riat market in kanyikela ward.\\n\\nmore info : Location : KENYA BidDate : 6/15/2020 Tender Country : KENYA Tender\\nType : Tenders Tendering Authority : County Government Of Homa Bay Tendering\\nAuthority Address : p.o box: 469-40300, homa-bay county, Financier : Self\\nFunded'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df_description['text'][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fencing of riat market in kanyikela ward.',\n",
       " 'more info : Location : KENYA BidDate : 6/15/2020 Tender Country : KENYA Tender\\nType : Tenders Tendering Authority : County Government Of Homa Bay Tendering\\nAuthority Address : p.o box: 469-40300, homa-bay county, Financier : Self\\nFunded']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Split Text into Sentences\n",
    "from nltk.tokenize import sent_tokenize # Return a sentence-tokenized copy of text\n",
    "sentences = []\n",
    "sentences.append(sent_tokenize(text))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fencing of riat market in kanyikela ward ',\n",
       " 'more info   location   kenya biddate             tender country   kenya tender type   tenders tendering authority   county government of homa bay tendering authority address   p o box             homa bay county  financier   self funded']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]\n",
    "\n",
    "clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AYAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fencing riat market kanyikela ward',\n",
       " 'info location kenya biddate tender country kenya tender type tenders tendering authority county government homa bay tendering authority address p box homa bay county financier self funded']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "\n",
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "\n",
    "clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Vocab Size ie size of dictionary. You can take any values. I am taking 10000 to vectorize words in to whole numbers\n",
    "vocab_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2964, 7017, 267, 4439, 1561], [4019, 9646, 2885, 8769, 6246, 6662, 2885, 6246, 3210, 5191, 1476, 3930, 221, 81, 6081, 8152, 1476, 3930, 3703, 6810, 3149, 6081, 8152, 221, 5388, 7032, 7358]]\n"
     ]
    }
   ],
   "source": [
    "# creating the one-hot Representation of the sentence\n",
    "onehot_rep=[one_hot(words,vocab_size) for words in clean_sentences]\n",
    "print(onehot_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biggest sentence has 187 words\n"
     ]
    }
   ],
   "source": [
    "largest_sen = max(len(sen) for sen in clean_sentences)\n",
    "print('biggest sentence has {} words'.format(largest_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the distribution of length of sentences\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist([len(s) for s in clean_sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2964 7017  267 4439 1561    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [4019 9646 2885 8769 6246 6662 2885 6246 3210 5191 1476 3930  221   81\n",
      "  6081 8152 1476 3930 3703 6810 3149 6081 8152  221 5388 7032 7358    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=100\n",
    "# padding to get equallength of sentences to fit in the model\n",
    "embedded_clean_sentence=pad_sequences(onehot_rep,maxlen=sent_length,padding=\"post\") \n",
    "print(embedded_clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now set the number of dimensions that we are gonna take as output\n",
    "dim_out=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AYAN\\anaconda3\\ANACONDA_NEW\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 10)           100000    \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating the model\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,dim_out,input_length=sent_length))\n",
    "model.compile('adam','mse')\n",
    "model.summary()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.0332253 ,  0.0198089 , -0.02061443, ..., -0.04215478,\n",
       "          0.00778729,  0.029387  ],\n",
       "        [ 0.00206959, -0.00168164, -0.02009743, ..., -0.00664544,\n",
       "         -0.007052  ,  0.03788393],\n",
       "        [ 0.00766461, -0.01771767, -0.04538345, ...,  0.0323525 ,\n",
       "         -0.04570911,  0.01682322],\n",
       "        ...,\n",
       "        [ 0.01311196,  0.02363357, -0.01415296, ..., -0.035518  ,\n",
       "          0.00340338,  0.03723482],\n",
       "        [ 0.01311196,  0.02363357, -0.01415296, ..., -0.035518  ,\n",
       "          0.00340338,  0.03723482],\n",
       "        [ 0.01311196,  0.02363357, -0.01415296, ..., -0.035518  ,\n",
       "          0.00340338,  0.03723482]],\n",
       "\n",
       "       [[-0.02960502, -0.02293292,  0.0363924 , ..., -0.01397467,\n",
       "          0.02008423,  0.0305662 ],\n",
       "        [-0.00993644,  0.047674  ,  0.04097516, ...,  0.02399175,\n",
       "         -0.045488  , -0.03902773],\n",
       "        [ 0.02777313,  0.01495535,  0.02657019, ...,  0.01728738,\n",
       "         -0.03371479,  0.04582741],\n",
       "        ...,\n",
       "        [ 0.01311196,  0.02363357, -0.01415296, ..., -0.035518  ,\n",
       "          0.00340338,  0.03723482],\n",
       "        [ 0.01311196,  0.02363357, -0.01415296, ..., -0.035518  ,\n",
       "          0.00340338,  0.03723482],\n",
       "        [ 0.01311196,  0.02363357, -0.01415296, ..., -0.035518  ,\n",
       "          0.00340338,  0.03723482]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'info location kenya biddate tender country kenya tender type tenders tendering authority county government homa bay tendering authority address p box homa bay county financier self funded'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4019, 9646, 2885, 8769, 6246, 6662, 2885, 6246, 3210, 5191, 1476,\n",
       "       3930,  221,   81, 6081, 8152, 1476, 3930, 3703, 6810, 3149, 6081,\n",
       "       8152,  221, 5388, 7032, 7358,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_clean_sentence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arary_1=model.predict(embedded_clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3465972"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight=np.sum(arary_1[0])\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list=[]\n",
    "sentence_list=[]\n",
    "for i in range(0,len(arary_1)):\n",
    "    weight_list.append(np.sum(arary_1[i]))\n",
    "    sentence_list.append(clean_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.3465972, 3.4431014]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fencing riat market kanyikela ward',\n",
       " 'info location kenya biddate tender country kenya tender type tenders tendering authority county government homa bay tendering authority address p box homa bay county financier self funded']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['sentence']=sentence_list\n",
    "df['weight']=weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>info location kenya biddate tender country ken...</td>\n",
       "      <td>3.443101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fencing riat market kanyikela ward</td>\n",
       "      <td>3.346597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    weight\n",
       "1  info location kenya biddate tender country ken...  3.443101\n",
       "0                 fencing riat market kanyikela ward  3.346597"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='weight',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fencing riat market kanyikela ward'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=10000\n",
    "dim_out=10\n",
    "sent_length=100\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,dim_out,input_length=sent_length))\n",
    "model.compile('adam','mse')\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "\n",
    "def text_summarization(text):\n",
    "    sentences = []\n",
    "    sentences.append(sent_tokenize(text))\n",
    "    sentences = [y for x in sentences for y in x] # flatten list\n",
    "    clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "    clean_sentences = [s.lower() for s in clean_sentences]\n",
    "    clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "\n",
    "    vocab_size=10000\n",
    "    onehot_rep=[one_hot(words,vocab_size) for words in clean_sentences]\n",
    "    sent_length=100\n",
    "    # padding to get equallength of sentences to fit in the model\n",
    "    embedded_clean_sentence=pad_sequences(onehot_rep,maxlen=sent_length,padding=\"post\") \n",
    "    arary_1=model.predict(embedded_clean_sentence)\n",
    "    weight_list=[]\n",
    "    sentence_list=[]\n",
    "    for i in range(0,len(arary_1)):\n",
    "        weight_list.append(np.sum(arary_1[i]))\n",
    "        sentence_list.append(clean_sentences[i])\n",
    "    df=pd.DataFrame()\n",
    "    df['sentence']=sentence_list\n",
    "    df['weight']=weight_list \n",
    "    \n",
    "    df.sort_values(by='weight',ascending=False)\n",
    " \n",
    "    return df['sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fencing of riat market in kanyikela ward.\\n\\nm...</td>\n",
       "      <td>fencing riat market kanyikela ward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VILNIUS, Jun 05, BNS - Visitors from low-risk ...</td>\n",
       "      <td>vilnius jun bns visitors low risk countries ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every year, Georgia yard sale shoppers spend t...</td>\n",
       "      <td>every year georgia yard sale shoppers spend fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adults have an opportunity to model good onlin...</td>\n",
       "      <td>adults opportunity model good online behavior ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company : OFFICE OF XINHE SUB-DISTRICT OFFICE,...</td>\n",
       "      <td>company office xinhe sub district office peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>According to [Kmov.com](http://Kmov.com), an a...</td>\n",
       "      <td>according kmov com http kmov com arrest made m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>PELHAM  For parent Daniela DeLuca, the Farewe...</td>\n",
       "      <td>pelham parent daniela deluca farewell parade h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Christine Blackburne The Associated Press\\n\\nP...</td>\n",
       "      <td>christine blackburne associated press phexxi c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Renewal of sports hall floor Viktoria elementa...</td>\n",
       "      <td>renewal sports hall floor viktoria elementary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>CINCINNATI \\- Hamilton County sheriff's deputi...</td>\n",
       "      <td>cincinnati hamilton county sheriff deputies fl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     fencing of riat market in kanyikela ward.\\n\\nm...   \n",
       "1     VILNIUS, Jun 05, BNS - Visitors from low-risk ...   \n",
       "2     Every year, Georgia yard sale shoppers spend t...   \n",
       "3     Adults have an opportunity to model good onlin...   \n",
       "4     Company : OFFICE OF XINHE SUB-DISTRICT OFFICE,...   \n",
       "...                                                 ...   \n",
       "1995  According to [Kmov.com](http://Kmov.com), an a...   \n",
       "1996  PELHAM  For parent Daniela DeLuca, the Farewe...   \n",
       "1997  Christine Blackburne The Associated Press\\n\\nP...   \n",
       "1998  Renewal of sports hall floor Viktoria elementa...   \n",
       "1999  CINCINNATI \\- Hamilton County sheriff's deputi...   \n",
       "\n",
       "                                                summary  \n",
       "0                    fencing riat market kanyikela ward  \n",
       "1     vilnius jun bns visitors low risk countries ou...  \n",
       "2     every year georgia yard sale shoppers spend fi...  \n",
       "3     adults opportunity model good online behavior ...  \n",
       "4     company office xinhe sub district office peopl...  \n",
       "...                                                 ...  \n",
       "1995  according kmov com http kmov com arrest made m...  \n",
       "1996  pelham parent daniela deluca farewell parade h...  \n",
       "1997  christine blackburne associated press phexxi c...  \n",
       "1998  renewal sports hall floor viktoria elementary ...  \n",
       "1999  cincinnati hamilton county sheriff deputies fl...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_description['summary']=df_description['text'].apply(text_summarization)\n",
    "df=df_description[['text','summary']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
